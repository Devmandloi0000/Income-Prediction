{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow of project\n",
    "- Understanding the Problem Statement or Insides Abouts The Data \n",
    "- Data Collection or Data Importing\n",
    "- Data Checks to perform\n",
    "- Exploratory data analysis (EDA)\n",
    "- Data Pre-Processing\n",
    "- Model Training\n",
    "- Selecting best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"E:\\\\Working\\\\Ineuron_intership\\\\notebook\\\\data\\\\adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week         country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We already perform some sort of opertaion on the data where we find some columns are negatively correlate with the Target column so we drop negative corr columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'education-num':\"education_num\",\n",
    "                   \"marital-status\":\"marital_status\",\n",
    "                   \"capital-gain\":\"capital_gain\",\n",
    "                   \"capital-loss\":\"capital_loss\",\n",
    "                   \"hours-per-week\":\"hours_per_week\"\n",
    "                   },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week         country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# education and education-num column describe the same so we should drop any one of them\n",
    "df.drop(labels=['education','fnlwgt','marital_status','relationship'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "education-num     0\n",
       "occupation        0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "country           0\n",
       "salary            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_change(test):\n",
    "    for req in test:\n",
    "        df[req].replace(\" ?\",np.NaN,inplace=True)\n",
    "        \n",
    "        \n",
    "get_change(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "education-num        0\n",
       "occupation        1843\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "country            583\n",
       "salary               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In both workclass and occupation both contain null values and there axis of both are same so its better to drop\n",
    "\n",
    "df.dropna(subset=['workclass','occupation'],inplace=True)\n",
    "\n",
    "val = str(df['country'].mode())\n",
    "\n",
    "df['country'].fillna(val,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are naming differnece \n",
    "\n",
    "df['country']=df['country'].replace({\"United-States\":\" United-States\",\n",
    "                                     \"0     United-States\\nName: country, dtype: object\":\" United-States\",\n",
    "                                     \" Outlying-US(Guam-USVI-etc)\":\" United-States\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_col=df.select_dtypes(include='O').columns\n",
    "num_col=df.select_dtypes(exclude='O').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(data):\n",
    "    for i in data:\n",
    "        #print(i)\n",
    "        df[i]=df[i].str.replace(\" \",\"\")\n",
    "        \n",
    "\n",
    "get_split(cate_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education-num         occupation   race     sex  \\\n",
       "0   39         State-gov             13       Adm-clerical  White    Male   \n",
       "1   50  Self-emp-not-inc             13    Exec-managerial  White    Male   \n",
       "2   38           Private              9  Handlers-cleaners  White    Male   \n",
       "3   53           Private              7  Handlers-cleaners  Black    Male   \n",
       "4   28           Private             13     Prof-specialty  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week        country salary  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nencoder = LabelEncoder()\\n\\ndf['race']=encoder.fit_transform(df['race'])\\ndf['sex']=encoder.fit_transform(df['sex'])\\ndf['salary']= encoder.fit_transform(df['salary'])\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traget column\n",
    "\"\"\"\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['race']=encoder.fit_transform(df['race'])\n",
    "df['sex']=encoder.fit_transform(df['sex'])\n",
    "df['salary']= encoder.fit_transform(df['salary'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "countery=df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "countery.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cambodia', 'Canada', 'China', 'Columbia', 'Cuba',\n",
       "       'Dominican-Republic', 'Ecuador', 'El-Salvador', 'England',\n",
       "       'France', 'Germany', 'Greece', 'Guatemala', 'Haiti',\n",
       "       'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n",
       "       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n",
       "       'Nicaragua', 'Peru', 'Philippines', 'Poland', 'Portugal',\n",
       "       'Puerto-Rico', 'Scotland', 'South', 'Taiwan', 'Thailand',\n",
       "       'Trinadad&Tobago', 'United-States', 'Vietnam', 'Yugoslavia'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {}\n",
    "\n",
    "def unique_list(data):\n",
    "    for i in data:\n",
    "        a=df[i].unique()\n",
    "        \n",
    "        report[i]=a\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights \n",
    "by using the dictionary we collect all the unique data from the dataset and update in report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workclass': array(['State-gov', 'Self-emp-not-inc', 'Private', 'Federal-gov',\n",
       "        'Local-gov', 'Self-emp-inc', 'Without-pay'], dtype=object),\n",
       " 'occupation': array(['Adm-clerical', 'Exec-managerial', 'Handlers-cleaners',\n",
       "        'Prof-specialty', 'Other-service', 'Sales', 'Craft-repair',\n",
       "        'Transport-moving', 'Farming-fishing', 'Machine-op-inspct',\n",
       "        'Tech-support', 'Protective-serv', 'Armed-Forces',\n",
       "        'Priv-house-serv'], dtype=object),\n",
       " 'race': array(['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo',\n",
       "        'Other'], dtype=object),\n",
       " 'sex': array(['Male', 'Female'], dtype=object),\n",
       " 'country': array(['United-States', 'Cuba', 'Jamaica', 'India', 'Mexico',\n",
       "        'Puerto-Rico', 'Honduras', 'England', 'Canada', 'Germany', 'Iran',\n",
       "        'Philippines', 'Poland', 'Columbia', 'Cambodia', 'Thailand',\n",
       "        'Ecuador', 'Laos', 'Taiwan', 'Haiti', 'Portugal',\n",
       "        'Dominican-Republic', 'El-Salvador', 'France', 'Guatemala',\n",
       "        'Italy', 'China', 'South', 'Japan', 'Yugoslavia', 'Peru',\n",
       "        'Scotland', 'Trinadad&Tobago', 'Greece', 'Nicaragua', 'Vietnam',\n",
       "        'Hong', 'Ireland', 'Hungary', 'Holand-Netherlands'], dtype=object),\n",
       " 'salary': array(['<=50K', '>50K'], dtype=object)}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_list(cate_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all are used for pipeline for the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='salary',axis=1)\n",
    "y = df.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>12</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>9</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30718 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  education-num         occupation   race     sex  \\\n",
       "0       39         State-gov             13       Adm-clerical  White    Male   \n",
       "1       50  Self-emp-not-inc             13    Exec-managerial  White    Male   \n",
       "2       38           Private              9  Handlers-cleaners  White    Male   \n",
       "3       53           Private              7  Handlers-cleaners  Black    Male   \n",
       "4       28           Private             13     Prof-specialty  Black  Female   \n",
       "...    ...               ...            ...                ...    ...     ...   \n",
       "32556   27           Private             12       Tech-support  White  Female   \n",
       "32557   40           Private              9  Machine-op-inspct  White    Male   \n",
       "32558   58           Private              9       Adm-clerical  White  Female   \n",
       "32559   22           Private              9       Adm-clerical  White    Male   \n",
       "32560   52      Self-emp-inc              9    Exec-managerial  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week        country  \n",
       "0              2174             0              40  United-States  \n",
       "1                 0             0              13  United-States  \n",
       "2                 0             0              40  United-States  \n",
       "3                 0             0              40  United-States  \n",
       "4                 0             0              40           Cuba  \n",
       "...             ...           ...             ...            ...  \n",
       "32556             0             0              38  United-States  \n",
       "32557             0             0              40  United-States  \n",
       "32558             0             0              40  United-States  \n",
       "32559             0             0              20  United-States  \n",
       "32560         15024             0              40  United-States  \n",
       "\n",
       "[30718 rows x 10 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2        <=50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "32556    <=50K\n",
       "32557     >50K\n",
       "32558    <=50K\n",
       "32559    <=50K\n",
       "32560     >50K\n",
       "Name: salary, Length: 30718, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_col=X.select_dtypes(include='O').columns\n",
    "num_col=X.select_dtypes(exclude='O').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights \n",
    "seprating data according to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['age', 'education-num', 'capital-gain', 'capital-loss',\n",
       "        'hours-per-week'],\n",
       "       dtype='object'),\n",
       " Index(['workclass', 'occupation', 'race', 'sex', 'country'], dtype='object'))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col,cate_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric and Categorical Columns Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create pipeline for numerical column and catogorical column for preprocess and missing value and ordinal ranking \n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy='median')),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "cate_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy='most_frequent')),\n",
    "        (\"ordinal_encoder\",OrdinalEncoder(categories=[report['workclass'],report['occupation'],report['race'],report['sex'],report['country']])),\n",
    "         (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_pipeline\",num_pipeline,num_col),\n",
    "    (\"cate_pipeline\",cate_pipeline,cate_col)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 Index([&#x27;age&#x27;, &#x27;education-num&#x27;, &#x27;capital-gain&#x27;, &#x27;capital-loss&#x27;,\n",
       "       &#x27;hours-per-week&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cate_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;ordinal_encoder&#x27;,\n",
       "                                                  OrdinalEncode...\n",
       "       &#x27;Ecuador&#x27;, &#x27;Laos&#x27;, &#x27;Taiwan&#x27;, &#x27;Haiti&#x27;, &#x27;Portugal&#x27;,\n",
       "       &#x27;Dominican-Republic&#x27;, &#x27;El-Salvador&#x27;, &#x27;France&#x27;, &#x27;Guatemala&#x27;,\n",
       "       &#x27;Italy&#x27;, &#x27;China&#x27;, &#x27;South&#x27;, &#x27;Japan&#x27;, &#x27;Yugoslavia&#x27;, &#x27;Peru&#x27;,\n",
       "       &#x27;Scotland&#x27;, &#x27;Trinadad&amp;Tobago&#x27;, &#x27;Greece&#x27;, &#x27;Nicaragua&#x27;, &#x27;Vietnam&#x27;,\n",
       "       &#x27;Hong&#x27;, &#x27;Ireland&#x27;, &#x27;Hungary&#x27;, &#x27;Holand-Netherlands&#x27;], dtype=object)])),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 Index([&#x27;workclass&#x27;, &#x27;occupation&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;country&#x27;], dtype=&#x27;object&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 Index([&#x27;age&#x27;, &#x27;education-num&#x27;, &#x27;capital-gain&#x27;, &#x27;capital-loss&#x27;,\n",
       "       &#x27;hours-per-week&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cate_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;ordinal_encoder&#x27;,\n",
       "                                                  OrdinalEncode...\n",
       "       &#x27;Ecuador&#x27;, &#x27;Laos&#x27;, &#x27;Taiwan&#x27;, &#x27;Haiti&#x27;, &#x27;Portugal&#x27;,\n",
       "       &#x27;Dominican-Republic&#x27;, &#x27;El-Salvador&#x27;, &#x27;France&#x27;, &#x27;Guatemala&#x27;,\n",
       "       &#x27;Italy&#x27;, &#x27;China&#x27;, &#x27;South&#x27;, &#x27;Japan&#x27;, &#x27;Yugoslavia&#x27;, &#x27;Peru&#x27;,\n",
       "       &#x27;Scotland&#x27;, &#x27;Trinadad&amp;Tobago&#x27;, &#x27;Greece&#x27;, &#x27;Nicaragua&#x27;, &#x27;Vietnam&#x27;,\n",
       "       &#x27;Hong&#x27;, &#x27;Ireland&#x27;, &#x27;Hungary&#x27;, &#x27;Holand-Netherlands&#x27;], dtype=object)])),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 Index([&#x27;workclass&#x27;, &#x27;occupation&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;country&#x27;], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;age&#x27;, &#x27;education-num&#x27;, &#x27;capital-gain&#x27;, &#x27;capital-loss&#x27;,\n",
       "       &#x27;hours-per-week&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cate_pipeline</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;workclass&#x27;, &#x27;occupation&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;country&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[array([&#x27;State-gov&#x27;, &#x27;Self-emp-not-inc&#x27;, &#x27;Private&#x27;, &#x27;Federal-gov&#x27;,\n",
       "       &#x27;Local-gov&#x27;, &#x27;Self-emp-inc&#x27;, &#x27;Without-pay&#x27;], dtype=object),\n",
       "                           array([&#x27;Adm-clerical&#x27;, &#x27;Exec-managerial&#x27;, &#x27;Handlers-cleaners&#x27;,\n",
       "       &#x27;Prof-specialty&#x27;, &#x27;Other-service&#x27;, &#x27;Sales&#x27;, &#x27;Craft-repair&#x27;,\n",
       "       &#x27;Transport-moving&#x27;, &#x27;Farming-fishing&#x27;, &#x27;Machine-op-inspct&#x27;,\n",
       "       &#x27;Tech-support&#x27;, &#x27;Protective-serv&#x27;...\n",
       "       &#x27;Puerto-Rico&#x27;, &#x27;Honduras&#x27;, &#x27;England&#x27;, &#x27;Canada&#x27;, &#x27;Germany&#x27;, &#x27;Iran&#x27;,\n",
       "       &#x27;Philippines&#x27;, &#x27;Poland&#x27;, &#x27;Columbia&#x27;, &#x27;Cambodia&#x27;, &#x27;Thailand&#x27;,\n",
       "       &#x27;Ecuador&#x27;, &#x27;Laos&#x27;, &#x27;Taiwan&#x27;, &#x27;Haiti&#x27;, &#x27;Portugal&#x27;,\n",
       "       &#x27;Dominican-Republic&#x27;, &#x27;El-Salvador&#x27;, &#x27;France&#x27;, &#x27;Guatemala&#x27;,\n",
       "       &#x27;Italy&#x27;, &#x27;China&#x27;, &#x27;South&#x27;, &#x27;Japan&#x27;, &#x27;Yugoslavia&#x27;, &#x27;Peru&#x27;,\n",
       "       &#x27;Scotland&#x27;, &#x27;Trinadad&amp;Tobago&#x27;, &#x27;Greece&#x27;, &#x27;Nicaragua&#x27;, &#x27;Vietnam&#x27;,\n",
       "       &#x27;Hong&#x27;, &#x27;Ireland&#x27;, &#x27;Hungary&#x27;, &#x27;Holand-Netherlands&#x27;], dtype=object)])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 Index(['age', 'education-num', 'capital-gain', 'capital-loss',\n",
       "       'hours-per-week'],\n",
       "      dtype='object')),\n",
       "                                ('cate_pipeline',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('ordinal_encoder',\n",
       "                                                  OrdinalEncode...\n",
       "       'Ecuador', 'Laos', 'Taiwan', 'Haiti', 'Portugal',\n",
       "       'Dominican-Republic', 'El-Salvador', 'France', 'Guatemala',\n",
       "       'Italy', 'China', 'South', 'Japan', 'Yugoslavia', 'Peru',\n",
       "       'Scotland', 'Trinadad&Tobago', 'Greece', 'Nicaragua', 'Vietnam',\n",
       "       'Hong', 'Ireland', 'Hungary', 'Holand-Netherlands'], dtype=object)])),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 Index(['workclass', 'occupation', 'race', 'sex', 'country'], dtype='object'))])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights \n",
    "\n",
    "    > Pipeline :- is used for makeing flow of data wheather it may be for categorical or numerical \n",
    "    > SimpleImputer :- Is used for handling Missing Values\n",
    "    > Standard Scaler :- Is used for scaling all the data into one fit\n",
    "    > OrdinalEncoder :- Is help us to convert data into numeric ranking as per we given list or ranking of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,\n",
    "                                               y,\n",
    "                                               test_size=0.3,\n",
    "                                               random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights \n",
    "train test split are used to used for training and testing purpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21502, 10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, 10)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21502,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_test=preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All model into a single dictionray\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\":LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier(),\n",
    "    \"svc\":SVC(),\n",
    "    \"RandomForestClassifier\":RandomForestClassifier(),\n",
    "    \"knn\": KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the model are at single dict and below function is used for to fit model and traing and testing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_evaluation(X_train,X_test,y_train,y_test,models):\n",
    "    model_rep = {}\n",
    "    training_rep = {}\n",
    "    scores = []\n",
    "    for i in range(len(models)):\n",
    "        model=list(models.values())[i]\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accu=accuracy_score(y_test,y_pred)\n",
    "        tran=model.score(X_train,y_train)\n",
    "        \n",
    "        model_rep[list(models.keys())[i]]=accu\n",
    "        training_rep[list(models.keys())[i]]=tran\n",
    "        \n",
    "        scores.append({\n",
    "            \"modeles\":list(models.keys())[i],\n",
    "            \"acc_score\":accuracy_score(y_test,y_pred),\n",
    "            \"train_score\":model.score(X_train,y_train)\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(scores,columns=['modeles','acc_score','train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modeles</th>\n",
       "      <th>acc_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.822049</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.790256</td>\n",
       "      <td>0.966329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.830078</td>\n",
       "      <td>0.838062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.827365</td>\n",
       "      <td>0.966329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.862059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  modeles  acc_score  train_score\n",
       "0      LogisticRegression   0.822049     0.821086\n",
       "1  DecisionTreeClassifier   0.790256     0.966329\n",
       "2                     svc   0.830078     0.838062\n",
       "3  RandomForestClassifier   0.827365     0.966329\n",
       "4                     knn   0.812500     0.862059"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(X_train,X_test,y_train,y_test,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy score and training score\n",
    "\n",
    "\n",
    "                            Modeles\t                acc_score\ttrain_score\n",
    "            \n",
    "            > 0\t        LogisticRegression\t    0.822049\t0.821086\n",
    "            > 1\t        DecisionTreeClassifier\t    0.790256\t0.966329\n",
    "            > 2\t        svc\t                    0.830078\t0.838062\n",
    "            > 3\t        RandomForestClassifier\t    0.827365\t0.966329\n",
    "            > 4\t        knn\t                    0.812500\t0.862059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this are the score of this so we can try with hyperparameters\n",
    "\n",
    "for better accuracy and overfitting we used hyperparameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.803 total time=   0.0s\n",
      "[CV 2/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.814 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.812 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.819 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.806 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.810 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l2, solver=liblinear;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=100, penalty=l1, solver=liblinear;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=l1, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=l1, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=l1, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=l1, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=100, penalty=l2, solver=liblinear;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=l2, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=l2, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=l2, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8219401041666666"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param = {\n",
    "    \"penalty\":['l1','l2'],\n",
    "    'C':[100,10,1,0.1,0.001],\n",
    "    \"solver\":['lbfgs','liblinear']\n",
    "}\n",
    "\n",
    "\n",
    "model1=LogisticRegression()\n",
    "\n",
    "\n",
    "logi_model = RandomizedSearchCV(\n",
    "                                estimator=model1,\n",
    "                                param_distributions=best_param,\n",
    "                                cv=5,\n",
    "                                scoring=\"accuracy\",\n",
    "                                verbose=5)\n",
    "\n",
    "logi_model.fit(X_train,y_train)\n",
    "y_pred=logi_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'liblinear', 'penalty': 'l1', 'C': 100}\n",
      "0.819969990753908\n"
     ]
    }
   ],
   "source": [
    "print(logi_model.best_params_)\n",
    "print(logi_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try hypertunning with the whole data by using the GridSearchCV \n",
    "\n",
    "    > GridSearchCV :- is usually best for small number of data but we have large data so can try with this  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(\n",
    "                        estimator=model1,\n",
    "                        param_grid=best_param,\n",
    "                        scoring=\"accuracy\",\n",
    "                        verbose=5,\n",
    "                        cv=5\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100, penalty=l1, solver=liblinear;, score=0.817 total time=   0.1s\n",
      "[CV 2/5] END C=100, penalty=l1, solver=liblinear;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END C=100, penalty=l1, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=l1, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=l1, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=100, penalty=l2, solver=liblinear;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=l2, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=l2, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=l2, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l1, solver=liblinear;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l1, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l1, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l1, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l1, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l2, solver=liblinear;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=1, penalty=l1, solver=liblinear;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END .C=1, penalty=l1, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END .C=1, penalty=l1, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END .C=1, penalty=l1, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .C=1, penalty=l1, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END .C=1, penalty=l2, solver=liblinear;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END .C=1, penalty=l2, solver=liblinear;, score=0.827 total time=   0.0s\n",
      "[CV 3/5] END .C=1, penalty=l2, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END .C=1, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END .C=1, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.827 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, penalty=l1, solver=liblinear;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, penalty=l1, solver=liblinear;, score=0.772 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, penalty=l1, solver=liblinear;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, penalty=l1, solver=liblinear;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.803 total time=   0.0s\n",
      "[CV 2/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.812 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.819 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.806 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, penalty=l2, solver=liblinear;, score=0.810 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8219401041666666"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)\n",
    "y_pred_grid = grid_model.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8200630031955793"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data=grid_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[100, 100, 100, 100, 10, 10, 10, 10, 1, 1, 1, 1, 0.1,\n",
       "                   0.1, 0.1, 0.1, 0.001, 0.001, 0.001, 0.001],\n",
       "             mask=[False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False, False, False, False, False,\n",
       "                   False, False, False, False],\n",
       "       fill_value='?',\n",
       "            dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data['param_C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0042007 , 0.10761724, 0.0709538 , 0.06360831, 0.00359435,\n",
       "        0.05382862, 0.061625  , 0.07039824, 0.00259972, 0.0592063 ,\n",
       "        0.05979676, 0.06620703, 0.00180054, 0.04780002, 0.06574998,\n",
       "        0.06600146, 0.00260205, 0.04800997, 0.05630875, 0.05719085]),\n",
       " 'std_fit_time': array([0.00159864, 0.03399071, 0.01194766, 0.00712197, 0.0013564 ,\n",
       "        0.00872393, 0.00825339, 0.01103968, 0.00079722, 0.01810924,\n",
       "        0.00159602, 0.0067936 , 0.00039923, 0.00337123, 0.00838018,\n",
       "        0.00641927, 0.0008019 , 0.00610109, 0.00377253, 0.00958244]),\n",
       " 'mean_score_time': array([0.        , 0.0166821 , 0.01020694, 0.01157832, 0.        ,\n",
       "        0.00944386, 0.00955052, 0.01080284, 0.        , 0.01179013,\n",
       "        0.00980263, 0.00972824, 0.        , 0.00959902, 0.01238384,\n",
       "        0.01239762, 0.        , 0.00987587, 0.01080818, 0.01220465]),\n",
       " 'std_score_time': array([0.        , 0.00681639, 0.00249045, 0.0022752 , 0.        ,\n",
       "        0.00068779, 0.00046225, 0.0014758 , 0.        , 0.00411864,\n",
       "        0.00098622, 0.00121664, 0.        , 0.00135801, 0.0035065 ,\n",
       "        0.00387559, 0.        , 0.00090239, 0.00133819, 0.00411345]),\n",
       " 'param_C': masked_array(data=[100, 100, 100, 100, 10, 10, 10, 10, 1, 1, 1, 1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1', 'l1',\n",
       "                    'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
       "                    'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
       "                    'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
       "                    'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
       "                    'liblinear', 'lbfgs', 'liblinear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 100, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}],\n",
       " 'split0_test_score': array([       nan, 0.81748431, 0.81748431, 0.81748431,        nan,\n",
       "        0.81748431, 0.81748431, 0.81748431,        nan, 0.81748431,\n",
       "        0.8172518 , 0.81748431,        nan, 0.81771681, 0.81794931,\n",
       "        0.81794931,        nan, 0.78191118, 0.80283655, 0.8116717 ]),\n",
       " 'split1_test_score': array([       nan, 0.82771449, 0.82771449, 0.82771449,        nan,\n",
       "        0.82771449, 0.82771449, 0.82771449,        nan, 0.82794699,\n",
       "        0.82748198, 0.82748198,        nan, 0.82724948, 0.82794699,\n",
       "        0.82817949,        nan, 0.78377122, 0.81074169, 0.81911183]),\n",
       " 'split2_test_score': array([       nan, 0.81372093, 0.81372093, 0.81372093,        nan,\n",
       "        0.81372093, 0.81372093, 0.81372093,        nan, 0.81372093,\n",
       "        0.81372093, 0.81372093,        nan, 0.81372093, 0.81348837,\n",
       "        0.81348837,        nan, 0.77232558, 0.80023256, 0.80604651]),\n",
       " 'split3_test_score': array([       nan, 0.82069767, 0.82069767, 0.82069767,        nan,\n",
       "        0.82069767, 0.82069767, 0.82069767,        nan, 0.82093023,\n",
       "        0.82046512, 0.82046512,        nan, 0.82069767, 0.82      ,\n",
       "        0.82      ,        nan, 0.78023256, 0.80465116, 0.81162791]),\n",
       " 'split4_test_score': array([       nan, 0.82      , 0.82      , 0.82      ,        nan,\n",
       "        0.82      , 0.82      , 0.82      ,        nan, 0.82023256,\n",
       "        0.82023256, 0.82023256,        nan, 0.82046512, 0.82      ,\n",
       "        0.82069767,        nan, 0.78255814, 0.80511628, 0.81      ]),\n",
       " 'mean_test_score': array([       nan, 0.81992348, 0.81992348, 0.81992348,        nan,\n",
       "        0.81992348, 0.81992348, 0.81992348,        nan, 0.820063  ,\n",
       "        0.81983048, 0.81987698,        nan, 0.81997   , 0.81987694,\n",
       "        0.82006297,        nan, 0.78015974, 0.80471565, 0.81169159]),\n",
       " 'std_test_score': array([       nan, 0.0045984 , 0.0045984 , 0.0045984 ,        nan,\n",
       "        0.0045984 , 0.0045984 , 0.0045984 ,        nan, 0.00468636,\n",
       "        0.00454062, 0.00451509,        nan, 0.00442478, 0.00468371,\n",
       "        0.00477447,        nan, 0.00408024, 0.00346719, 0.00423776]),\n",
       " 'rank_test_score': array([16,  4,  4,  4, 16,  4,  4,  4, 16,  1, 12, 10, 16,  3, 11,  2, 16,\n",
       "        15, 14, 13])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END criterion=entropy, max_depth=20, min_samples_leaf=12, min_samples_split=16, splitter=best;, score=0.827 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=20, min_samples_leaf=12, min_samples_split=16, splitter=best;, score=0.830 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=20, min_samples_leaf=12, min_samples_split=16, splitter=best;, score=0.822 total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=1, min_samples_leaf=5, min_samples_split=2, splitter=best;, score=0.794 total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=1, min_samples_leaf=5, min_samples_split=2, splitter=best;, score=0.794 total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=1, min_samples_leaf=5, min_samples_split=2, splitter=best;, score=0.795 total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2, splitter=best;, score=0.821 total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2, splitter=best;, score=0.826 total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2, splitter=best;, score=0.822 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=1, min_samples_leaf=1, min_samples_split=8, splitter=random;, score=0.751 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=1, min_samples_leaf=1, min_samples_split=8, splitter=random;, score=0.751 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=1, min_samples_leaf=1, min_samples_split=8, splitter=random;, score=0.751 total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=1, min_samples_leaf=5, min_samples_split=20, splitter=best;, score=0.794 total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=1, min_samples_leaf=5, min_samples_split=20, splitter=best;, score=0.794 total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=1, min_samples_leaf=5, min_samples_split=20, splitter=best;, score=0.795 total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.806 total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.802 total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.790 total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=16, splitter=best;, score=0.836 total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=16, splitter=best;, score=0.835 total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=16, splitter=best;, score=0.836 total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=8, splitter=random;, score=0.824 total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=8, splitter=random;, score=0.817 total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=8, splitter=random;, score=0.816 total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=1, min_samples_leaf=10, min_samples_split=8, splitter=random;, score=0.751 total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=1, min_samples_leaf=10, min_samples_split=8, splitter=random;, score=0.751 total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=1, min_samples_leaf=10, min_samples_split=8, splitter=random;, score=0.751 total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=8, splitter=best;, score=0.812 total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=8, splitter=best;, score=0.815 total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=8, splitter=best;, score=0.801 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.833984375"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "best_para = {\n",
    "    \"criterion\":['gini',\"entropy\"],\n",
    "    \"splitter\":['best','random'],\n",
    "    \"max_depth\":[1,10,20,50],\n",
    "    \"min_samples_split\":[2,8,16,20],\n",
    "    \"min_samples_leaf\":[1,5,10,12]\n",
    "}\n",
    "\n",
    "\n",
    "model_search = RandomizedSearchCV(\n",
    "                                estimator=model_dt,\n",
    "                                param_distributions=best_para,\n",
    "                                scoring=\"accuracy\",\n",
    "                                verbose=3,\n",
    "                                cv=3\n",
    "                                )\n",
    "\n",
    "\n",
    "model_search.fit(X_train,y_train)\n",
    "y_pred_dt = model_search.predict(X_test)\n",
    "accuracy_score(y_test,y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_leaf=5,\n",
       "                       min_samples_split=16, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_leaf=5,\n",
       "                       min_samples_split=16, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=5,\n",
       "                       min_samples_split=16, random_state=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'splitter': 'best',\n",
       " 'min_samples_split': 16,\n",
       " 'min_samples_leaf': 5,\n",
       " 'max_depth': 10,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356431822938468"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END C=0.0001, decision_function_shape=ovr, kernel=rbf;, score=0.751 total time=  12.8s\n",
      "[CV 2/5] END C=0.0001, decision_function_shape=ovr, kernel=rbf;, score=0.751 total time=  12.9s\n",
      "[CV 3/5] END C=0.0001, decision_function_shape=ovr, kernel=rbf;, score=0.751 total time=  11.4s\n",
      "[CV 4/5] END C=0.0001, decision_function_shape=ovr, kernel=rbf;, score=0.751 total time=  14.4s\n",
      "[CV 5/5] END C=0.0001, decision_function_shape=ovr, kernel=rbf;, score=0.751 total time=  12.6s\n",
      "[CV 1/5] END C=0.01, decision_function_shape=ovo, kernel=poly;, score=0.777 total time=   7.5s\n",
      "[CV 2/5] END C=0.01, decision_function_shape=ovo, kernel=poly;, score=0.784 total time=   7.3s\n",
      "[CV 3/5] END C=0.01, decision_function_shape=ovo, kernel=poly;, score=0.774 total time=   6.5s\n",
      "[CV 4/5] END C=0.01, decision_function_shape=ovo, kernel=poly;, score=0.782 total time=   6.7s\n",
      "[CV 5/5] END C=0.01, decision_function_shape=ovo, kernel=poly;, score=0.781 total time=   6.7s\n",
      "[CV 1/5] END C=0.0001, decision_function_shape=ovo, kernel=poly;, score=0.758 total time=   6.2s\n",
      "[CV 2/5] END C=0.0001, decision_function_shape=ovo, kernel=poly;, score=0.758 total time=   6.9s\n",
      "[CV 3/5] END C=0.0001, decision_function_shape=ovo, kernel=poly;, score=0.754 total time=   6.0s\n",
      "[CV 4/5] END C=0.0001, decision_function_shape=ovo, kernel=poly;, score=0.756 total time=   6.1s\n",
      "[CV 5/5] END C=0.0001, decision_function_shape=ovo, kernel=poly;, score=0.755 total time=   6.2s\n",
      "[CV 1/5] END C=0.0001, decision_function_shape=ovr, kernel=poly;, score=0.758 total time=   6.1s\n",
      "[CV 2/5] END C=0.0001, decision_function_shape=ovr, kernel=poly;, score=0.758 total time=   6.5s\n",
      "[CV 3/5] END C=0.0001, decision_function_shape=ovr, kernel=poly;, score=0.754 total time=   6.0s\n",
      "[CV 4/5] END C=0.0001, decision_function_shape=ovr, kernel=poly;, score=0.756 total time=   6.2s\n",
      "[CV 5/5] END C=0.0001, decision_function_shape=ovr, kernel=poly;, score=0.755 total time=   6.3s\n",
      "[CV 1/5] END C=1, decision_function_shape=ovo, kernel=rbf;, score=0.831 total time=  10.9s\n",
      "[CV 2/5] END C=1, decision_function_shape=ovo, kernel=rbf;, score=0.836 total time=  10.8s\n",
      "[CV 3/5] END C=1, decision_function_shape=ovo, kernel=rbf;, score=0.828 total time=  10.5s\n",
      "[CV 4/5] END C=1, decision_function_shape=ovo, kernel=rbf;, score=0.830 total time=  10.6s\n",
      "[CV 5/5] END C=1, decision_function_shape=ovo, kernel=rbf;, score=0.834 total time=  10.6s\n",
      "[CV 1/5] END C=0.01, decision_function_shape=ovr, kernel=rbf;, score=0.781 total time=  10.9s\n",
      "[CV 2/5] END C=0.01, decision_function_shape=ovr, kernel=rbf;, score=0.779 total time=  11.3s\n",
      "[CV 3/5] END C=0.01, decision_function_shape=ovr, kernel=rbf;, score=0.780 total time=  11.9s\n",
      "[CV 4/5] END C=0.01, decision_function_shape=ovr, kernel=rbf;, score=0.786 total time=  11.5s\n",
      "[CV 5/5] END C=0.01, decision_function_shape=ovr, kernel=rbf;, score=0.782 total time=  11.8s\n",
      "[CV 1/5] END C=0.01, decision_function_shape=ovo, kernel=rbf;, score=0.781 total time=  10.8s\n",
      "[CV 2/5] END C=0.01, decision_function_shape=ovo, kernel=rbf;, score=0.779 total time=  10.9s\n",
      "[CV 3/5] END C=0.01, decision_function_shape=ovo, kernel=rbf;, score=0.780 total time=  11.4s\n",
      "[CV 4/5] END C=0.01, decision_function_shape=ovo, kernel=rbf;, score=0.786 total time=  10.9s\n",
      "[CV 5/5] END C=0.01, decision_function_shape=ovo, kernel=rbf;, score=0.782 total time=  13.9s\n",
      "[CV 1/5] END C=1, decision_function_shape=ovr, kernel=rbf;, score=0.831 total time=  13.3s\n",
      "[CV 2/5] END C=1, decision_function_shape=ovr, kernel=rbf;, score=0.836 total time=  10.2s\n",
      "[CV 3/5] END C=1, decision_function_shape=ovr, kernel=rbf;, score=0.828 total time=  10.0s\n",
      "[CV 4/5] END C=1, decision_function_shape=ovr, kernel=rbf;, score=0.830 total time=  10.6s\n",
      "[CV 5/5] END C=1, decision_function_shape=ovr, kernel=rbf;, score=0.834 total time=  12.2s\n",
      "[CV 1/5] END C=0.0001, decision_function_shape=ovo, kernel=rbf;, score=0.751 total time=  12.1s\n",
      "[CV 2/5] END C=0.0001, decision_function_shape=ovo, kernel=rbf;, score=0.751 total time=  11.5s\n",
      "[CV 3/5] END C=0.0001, decision_function_shape=ovo, kernel=rbf;, score=0.751 total time=  11.0s\n",
      "[CV 4/5] END C=0.0001, decision_function_shape=ovo, kernel=rbf;, score=0.751 total time=  10.7s\n",
      "[CV 5/5] END C=0.0001, decision_function_shape=ovo, kernel=rbf;, score=0.751 total time=  13.0s\n",
      "[CV 1/5] END C=0.01, decision_function_shape=ovr, kernel=poly;, score=0.777 total time=   6.7s\n",
      "[CV 2/5] END C=0.01, decision_function_shape=ovr, kernel=poly;, score=0.784 total time=   6.7s\n",
      "[CV 3/5] END C=0.01, decision_function_shape=ovr, kernel=poly;, score=0.774 total time=   6.7s\n",
      "[CV 4/5] END C=0.01, decision_function_shape=ovr, kernel=poly;, score=0.782 total time=   6.8s\n",
      "[CV 5/5] END C=0.01, decision_function_shape=ovr, kernel=poly;, score=0.781 total time=   6.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.830078125"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc = SVC()\n",
    "\n",
    "best_parameters = {\n",
    "    \"C\":[1,0.01,0.0001],\n",
    "    \"kernel\":['rbf','poly'],\n",
    "    \"decision_function_shape\":['ovr','ovo']\n",
    "}\n",
    "\n",
    "\n",
    "model_svc = RandomizedSearchCV(estimator=model_svc,\n",
    "                               param_distributions=best_parameters,\n",
    "                               scoring=\"accuracy\",\n",
    "                               cv=5,\n",
    "                               verbose=3\n",
    "                               )\n",
    "\n",
    "model_svc.fit(X_train,y_train)\n",
    "y_pred_svc=model_svc.predict(X_test)\n",
    "accuracy_score(y_test,y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, decision_function_shape=&#x27;ovo&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, decision_function_shape=&#x27;ovo&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, decision_function_shape='ovo')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'decision_function_shape': 'ovo', 'C': 1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380615756673798"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8318294393407697"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging :- Boostrap and Aggression methods are helps to get sample from the data and get select majority of the vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_randomforest = RandomForestClassifier()\n",
    "\n",
    "best_para = {\n",
    "    \"n_estimators\":[20,200,250,350],\n",
    "    \"criterion\":['gini','entropy'],\n",
    "    \"max_depth\":[1,5,10,15,45,75,150,250],\n",
    "    \"min_samples_split\":[1,5,10,15,20,25],\n",
    "    \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=9, min_samples_split=1, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=9, min_samples_split=1, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=9, min_samples_split=1, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=45, min_samples_leaf=8, min_samples_split=5, n_estimators=200;, score=0.844 total time=   2.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=45, min_samples_leaf=8, min_samples_split=5, n_estimators=200;, score=0.841 total time=   2.5s\n",
      "[CV 3/3] END criterion=entropy, max_depth=45, min_samples_leaf=8, min_samples_split=5, n_estimators=200;, score=0.844 total time=   2.7s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=20;, score=0.836 total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=20;, score=0.826 total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10, n_estimators=20;, score=0.829 total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=7, min_samples_split=5, n_estimators=20;, score=0.844 total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=7, min_samples_split=5, n_estimators=20;, score=0.840 total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=7, min_samples_split=5, n_estimators=20;, score=0.842 total time=   0.3s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, min_samples_leaf=8, min_samples_split=5, n_estimators=250;, score=0.835 total time=   1.4s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, min_samples_leaf=8, min_samples_split=5, n_estimators=250;, score=0.831 total time=   1.7s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, min_samples_leaf=8, min_samples_split=5, n_estimators=250;, score=0.836 total time=   1.8s\n",
      "[CV 1/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=20, n_estimators=200;, score=0.844 total time=   2.7s\n",
      "[CV 2/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=20, n_estimators=200;, score=0.842 total time=   2.4s\n",
      "[CV 3/3] END criterion=entropy, max_depth=15, min_samples_leaf=4, min_samples_split=20, n_estimators=200;, score=0.844 total time=   2.6s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20;, score=0.836 total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20;, score=0.830 total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20;, score=0.833 total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=10, min_samples_leaf=7, min_samples_split=20, n_estimators=250;, score=0.844 total time=   2.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=10, min_samples_leaf=7, min_samples_split=20, n_estimators=250;, score=0.837 total time=   2.5s\n",
      "[CV 3/3] END criterion=entropy, max_depth=10, min_samples_leaf=7, min_samples_split=20, n_estimators=250;, score=0.842 total time=   2.4s\n",
      "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=1, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=1, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=1, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=15, n_estimators=250;, score=0.843 total time=   2.7s\n",
      "[CV 2/3] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=15, n_estimators=250;, score=0.841 total time=   3.3s\n",
      "[CV 3/3] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=15, n_estimators=250;, score=0.841 total time=   3.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8432074652777778"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomizedSearchCV(estimator=model_randomforest,\n",
    "                              param_distributions=best_para,\n",
    "                              scoring=\"accuracy\",\n",
    "                              cv=3,\n",
    "                              verbose=3\n",
    "                              )\n",
    "\n",
    "model_rf.fit(X_train,y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, min_samples_leaf=4,\n",
       "                       min_samples_split=20, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, min_samples_leaf=4,\n",
       "                       min_samples_split=20, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=15, min_samples_leaf=4,\n",
       "                       min_samples_split=20, n_estimators=200)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 20,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_depth': 15,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8433633965633658"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8592689052181193"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by using bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bagging = BaggingClassifier(estimator=SVC(),bootstrap=True)\n",
    "\n",
    "best_parameters_bag = {\n",
    "    \"n_estimators\":[10,15,20,25,30],\n",
    "    \"max_samples\":[10,15,20,25,30],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomizedSearchCV(\n",
    "                        estimator=model_bagging,\n",
    "                        param_distributions=best_parameters_bag,\n",
    "                        scoring=\"accuracy\",\n",
    "                        cv=3,\n",
    "                        verbose=3\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END ...max_samples=30, n_estimators=25;, score=0.751 total time=   0.8s\n",
      "[CV 2/3] END ...max_samples=30, n_estimators=25;, score=0.751 total time=   0.6s\n",
      "[CV 3/3] END ...max_samples=30, n_estimators=25;, score=0.751 total time=   0.6s\n",
      "[CV 1/3] END .....max_samples=10, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....max_samples=10, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...max_samples=10, n_estimators=20;, score=0.751 total time=   0.4s\n",
      "[CV 1/3] END ...max_samples=20, n_estimators=15;, score=0.751 total time=   0.3s\n",
      "[CV 2/3] END ...max_samples=20, n_estimators=15;, score=0.751 total time=   0.3s\n",
      "[CV 3/3] END ...max_samples=20, n_estimators=15;, score=0.753 total time=   0.3s\n",
      "[CV 1/3] END .....max_samples=10, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...max_samples=10, n_estimators=10;, score=0.751 total time=   0.2s\n",
      "[CV 3/3] END .....max_samples=10, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...max_samples=20, n_estimators=30;, score=0.751 total time=   0.7s\n",
      "[CV 2/3] END ...max_samples=20, n_estimators=30;, score=0.751 total time=   0.6s\n",
      "[CV 3/3] END ...max_samples=20, n_estimators=30;, score=0.751 total time=   0.7s\n",
      "[CV 1/3] END ...max_samples=25, n_estimators=20;, score=0.751 total time=   0.5s\n",
      "[CV 2/3] END ...max_samples=25, n_estimators=20;, score=0.751 total time=   0.5s\n",
      "[CV 3/3] END ...max_samples=25, n_estimators=20;, score=0.751 total time=   0.5s\n",
      "[CV 1/3] END ...max_samples=15, n_estimators=10;, score=0.751 total time=   0.1s\n",
      "[CV 2/3] END ...max_samples=15, n_estimators=10;, score=0.751 total time=   0.2s\n",
      "[CV 3/3] END ...max_samples=15, n_estimators=10;, score=0.751 total time=   0.2s\n",
      "[CV 1/3] END ...max_samples=10, n_estimators=15;, score=0.751 total time=   0.2s\n",
      "[CV 2/3] END .....max_samples=10, n_estimators=15;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....max_samples=10, n_estimators=15;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...max_samples=15, n_estimators=15;, score=0.751 total time=   0.3s\n",
      "[CV 2/3] END ...max_samples=15, n_estimators=15;, score=0.751 total time=   0.3s\n",
      "[CV 3/3] END ...max_samples=15, n_estimators=15;, score=0.751 total time=   0.3s\n",
      "[CV 1/3] END ...max_samples=20, n_estimators=25;, score=0.751 total time=   0.6s\n",
      "[CV 2/3] END ...max_samples=20, n_estimators=25;, score=0.751 total time=   0.6s\n",
      "[CV 3/3] END ...max_samples=20, n_estimators=25;, score=0.751 total time=   0.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7506510416666666"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510929215886895"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=SVC(), max_samples=20, n_estimators=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=SVC(), max_samples=20, n_estimators=15)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=SVC(), max_samples=20, n_estimators=15)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 15, 'max_samples': 20}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519300908761718"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [{\n",
    "    \"LogisticRegression\":LogisticRegression(solver='liblinear',penalty=\"l2\",C=0.1),\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier(min_samples_split=16,min_samples_leaf=1,max_depth=10,criterion='entropy',splitter='best'),\n",
    "    \"svc\":SVC(kernel='rbf',decision_function_shape='ovo',C=1),\n",
    "    \"RandomForestClassifier\":RandomForestClassifier(n_estimators=250,min_samples_split=10,min_samples_leaf=8,max_depth=250,criterion='entropy'),\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = []\n",
    "def model_eva(models):\n",
    "    for i,j in models.items():\n",
    "        model = models[i]\n",
    "        \n",
    "        search = VotingClassifier(\n",
    "                                estimators=[\n",
    "                                    ('lr',LogisticRegression(solver='liblinear',penalty=\"l2\",C=0.1)),\n",
    "                                    (\"dc\",DecisionTreeClassifier(min_samples_split=16,min_samples_leaf=1,max_depth=10,criterion='entropy',splitter='best'))\n",
    "                                ],\n",
    "                                voting='hard'\n",
    "                                )\n",
    "        \n",
    "        search.fit(X_train,y_train)\n",
    "        y_pred=search.predict(X_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        accu = accuracy_score(y_test, y_pred)\n",
    "        tran = search.score(X_train, y_train)\n",
    "    \n",
    "\n",
    "        rep.append({\n",
    "            \"model\": j,\n",
    "            \"acc_score\": accu,\n",
    "            \"train_score\": tran\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'LogisticRegression': LogisticRegression(C=0.1, solver='liblinear'),\n",
       "  'DecisionTreeClassifier': DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=16),\n",
       "  'svc': SVC(C=1, decision_function_shape='ovo'),\n",
       "  'RandomForestClassifier': RandomForestClassifier(criterion='entropy', max_depth=250, min_samples_leaf=8,\n",
       "                         min_samples_split=10, n_estimators=250)}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = [LogisticRegression(),DecisionTreeClassifier(),SVC(),RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StackingClassifier(estimators=[\n",
    "                                        ('lg',LogisticRegression(C=0.1, solver='liblinear')),\n",
    "                                        ('dc',DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=16)),\n",
    "                                        ('svc',SVC(C=1, decision_function_shape='ovo')),\n",
    "                                        (\"rf\",RandomForestClassifier(criterion='entropy', max_depth=250, min_samples_leaf=8,min_samples_split=10, n_estimators=250))\n",
    "                            ],\n",
    "                           final_estimator=DecisionTreeClassifier(),\n",
    "                           cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7870008680555556"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7870008680555556"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For all hyperparam tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Hyperparameter dictionary\\nmodel_dict ={\\n    \\n    \"LR\":[{\\n            \"penalty\":[\\'l1\\',\\'l2\\'],\\n            \\'C\\':[100,10,1,0.1,0.001],\\n            \"solver\":[\\'lbfgs\\',\\'liblinear\\']\\n            }],\\n    \\n    \\n    \"DC\":[{\\n            \"criterion\":[\\'gini\\',\"entropy\"],\\n            \"splitter\":[\\'best\\',\\'random\\'],\\n            \"max_depth\":[1,10,20,50],\\n            \"min_samples_split\":[2,8,16,20],\\n            \"min_samples_leaf\":[1,5,10,12]\\n            }],\\n    \\n    \\n    \"SVC\":[{\\n            \"C\":[1,0.01,0.0001],\\n            \"kernel\":[\\'rbf\\',\\'poly\\'],\\n            \"decision_function_shape\":[\\'ovr\\',\\'ovo\\']\\n            }],\\n    \\n    \\n    \"RF\" : [{\\n            \"n_estimators\":[20,200,250,350],\\n            \"criterion\":[\\'gini\\',\\'entropy\\'],\\n            \"max_depth\":[1,5,10,15,45,75,150,250],\\n            \"min_samples_split\":[1,5,10,15,20,25],\\n            \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10]\\n            }]\\n    \\n            }\\n\\n\\n\\n# Models \\nmodels = {\\n    \"LogisticRegression\":LogisticRegression(),\\n    \"DecisionTreeClassifier\":DecisionTreeClassifier(),\\n    \"svc\":SVC(),\\n    \"RandomForestClassifier\":RandomForestClassifier(),\\n}\\n\\n\\n# global list\\nscores = []\\ndef model_evaluation(\\n                    X_train,\\n                    X_test,\\n                    y_train,\\n                    y_test,\\n                    models,\\n                    model_dict\\n                    ):\\n    model_rep = {}\\n    training_rep = {}\\n    \\n    for i in range(len(models)):\\n        model=list(models.values())[i]\\n        \\n        #if model == \"\"\\n        \\n        model = RandomizedSearchCV(\\n                                    estimator=model,\\n                                    param_distributions= \"----\",\\n                                    scoring=\"accuracy\",\\n                                    cv=5\\n                                    )\\n        model.fit(X_train,y_train)\\n        \\n        y_pred = model.predict(X_test)\\n        \\n        accu=accuracy_score(y_test,y_pred)\\n        tran=model.score(X_train,y_train)\\n        \\n        model_rep[list(models.keys())[i]]=accu\\n        training_rep[list(models.keys())[i]]=tran\\n        \\n        scores.append({\\n            \"modeles\":list(models.keys())[i],\\n            \"acc_score\":accuracy_score(y_test,y_pred),\\n            \"train_score\":model.score(X_train,y_train)\\n        })\\n        \\n    return pd.DataFrame(scores,columns=[\\'modeles\\',\\'acc_score\\',\\'train_score\\'])\\n    \\n    \\n    '"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Hyperparameter dictionary\n",
    "model_dict ={\n",
    "    \n",
    "    \"LR\":[{\n",
    "            \"penalty\":['l1','l2'],\n",
    "            'C':[100,10,1,0.1,0.001],\n",
    "            \"solver\":['lbfgs','liblinear']\n",
    "            }],\n",
    "    \n",
    "    \n",
    "    \"DC\":[{\n",
    "            \"criterion\":['gini',\"entropy\"],\n",
    "            \"splitter\":['best','random'],\n",
    "            \"max_depth\":[1,10,20,50],\n",
    "            \"min_samples_split\":[2,8,16,20],\n",
    "            \"min_samples_leaf\":[1,5,10,12]\n",
    "            }],\n",
    "    \n",
    "    \n",
    "    \"SVC\":[{\n",
    "            \"C\":[1,0.01,0.0001],\n",
    "            \"kernel\":['rbf','poly'],\n",
    "            \"decision_function_shape\":['ovr','ovo']\n",
    "            }],\n",
    "    \n",
    "    \n",
    "    \"RF\" : [{\n",
    "            \"n_estimators\":[20,200,250,350],\n",
    "            \"criterion\":['gini','entropy'],\n",
    "            \"max_depth\":[1,5,10,15,45,75,150,250],\n",
    "            \"min_samples_split\":[1,5,10,15,20,25],\n",
    "            \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10]\n",
    "            }]\n",
    "    \n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "# Models \n",
    "models = {\n",
    "    \"LogisticRegression\":LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier(),\n",
    "    \"svc\":SVC(),\n",
    "    \"RandomForestClassifier\":RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "\n",
    "# global list\n",
    "scores = []\n",
    "def model_evaluation(\n",
    "                    X_train,\n",
    "                    X_test,\n",
    "                    y_train,\n",
    "                    y_test,\n",
    "                    models,\n",
    "                    model_dict\n",
    "                    ):\n",
    "    model_rep = {}\n",
    "    training_rep = {}\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        model=list(models.values())[i]\n",
    "        \n",
    "        #if model == \"\"\n",
    "        \n",
    "        model = RandomizedSearchCV(\n",
    "                                    estimator=model,\n",
    "                                    param_distributions= \"----\",\n",
    "                                    scoring=\"accuracy\",\n",
    "                                    cv=5\n",
    "                                    )\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accu=accuracy_score(y_test,y_pred)\n",
    "        tran=model.score(X_train,y_train)\n",
    "        \n",
    "        model_rep[list(models.keys())[i]]=accu\n",
    "        training_rep[list(models.keys())[i]]=tran\n",
    "        \n",
    "        scores.append({\n",
    "            \"modeles\":list(models.keys())[i],\n",
    "            \"acc_score\":accuracy_score(y_test,y_pred),\n",
    "            \"train_score\":model.score(X_train,y_train)\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(scores,columns=['modeles','acc_score','train_score'])\n",
    "    \n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tunning\n",
    "\n",
    "here we are using different different model with hyper parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter dictionaries for each model\n",
    "best_param_LR = {\n",
    "    \"penalty\": ['l1', 'l2'],\n",
    "    'C': [100, 10, 1, 0.1, 0.001],\n",
    "    \"solver\": ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "best_param_DC = {\n",
    "    \"criterion\": ['gini', \"entropy\"],\n",
    "    \"splitter\": ['best', 'random'],\n",
    "    \"max_depth\": [1, 10, 20, 50],\n",
    "    \"min_samples_split\": [2, 8, 16, 20],\n",
    "    \"min_samples_leaf\": [1, 5, 10, 12]\n",
    "}\n",
    "\n",
    "best_param_SVC = {\n",
    "    \"C\": [1, 0.01, 0.0001],\n",
    "    \"kernel\": ['rbf', 'poly'],\n",
    "    \"decision_function_shape\": ['ovr', 'ovo']\n",
    "}\n",
    "\n",
    "best_param_RF = {\n",
    "    \"n_estimators\": [20, 200, 250, 350],\n",
    "    \"criterion\": ['gini', 'entropy'],\n",
    "    \"max_depth\": [1, 5, 10, 15, 45, 75, 150, 250],\n",
    "    \"min_samples_split\": [1, 5, 10, 15, 20, 25],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "# Create models\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "scores = []\n",
    "def model_evaluate(\n",
    "                    X_train,\n",
    "                    X_test,\n",
    "                    y_train,\n",
    "                    y_test,\n",
    "                    models\n",
    "                    ):\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        if model_name == \"LogisticRegression\":\n",
    "            hyperparameters = best_param_LR\n",
    "        elif model_name == \"DecisionTreeClassifier\":\n",
    "            hyperparameters = best_param_DC\n",
    "        elif model_name == \"SVC\":\n",
    "            hyperparameters = best_param_SVC\n",
    "        elif model_name == \"RandomForestClassifier\":\n",
    "            hyperparameters = best_param_RF\n",
    "\n",
    "        # Perform hyperparameter tuning using GridSearchCV or RandomizedSearchCV\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=model,\n",
    "            param_distributions=hyperparameters,\n",
    "            scoring=\"accuracy\",\n",
    "            cv=5,\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = search.predict(X_test)\n",
    "        accu = accuracy_score(y_test, y_pred)\n",
    "        tran = search.score(X_train, y_train)\n",
    "        para = search.best_params_,\n",
    "        best_sc = search.best_score_\n",
    "\n",
    "        scores.append({\n",
    "            \"model\": model_name,\n",
    "            \"acc_score\": accu,\n",
    "            \"train_score\": tran,\n",
    "            \"best_param\":para,\n",
    "            \"best_sc\":best_sc\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame to display the results\n",
    "    results = pd.DataFrame(scores, columns=['model', 'acc_score', 'train_score','best_para','best_sc'])\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model  acc_score  train_score  best_para   best_sc\n",
      "0      LogisticRegression   0.821940     0.821086        NaN  0.820063\n",
      "1  DecisionTreeClassifier   0.833767     0.845642        NaN  0.836387\n",
      "2                     SVC   0.830078     0.838062        NaN  0.831829\n",
      "3  RandomForestClassifier   0.843099     0.887917        NaN  0.844759\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(X_train,X_test,y_train,y_test,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Training Score by Hyperparameter Tuning\n",
    "\n",
    "                              model  acc_score  train_score  best_para   best_sc\n",
    "                              \n",
    "        > 0      LogisticRegression   0.821940     0.821086        NaN  0.820063\n",
    "        > 1  DecisionTreeClassifier   0.833767     0.845642        NaN  0.836387\n",
    "        > 2                     SVC   0.830078     0.838062        NaN  0.831829\n",
    "        > 3  RandomForestClassifier   0.843099     0.887917        NaN  0.844759\n",
    "\n",
    "\n",
    "#### Conclusion :-\n",
    "\n",
    "SVC or Random Forest Classfier give us best training and testing accuracy so finally we are going with any one of them \n",
    "\n",
    "Ensemble methods are not giving such accuracy with training data so we are not using them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'LogisticRegression',\n",
       "  'acc_score': 0.8219401041666666,\n",
       "  'train_score': 0.8210864105664589,\n",
       "  'best_param': ({'solver': 'liblinear', 'penalty': 'l1', 'C': 1},),\n",
       "  'best_sc': 0.8200630031955793},\n",
       " {'model': 'DecisionTreeClassifier',\n",
       "  'acc_score': 0.8337673611111112,\n",
       "  'train_score': 0.8456422658357362,\n",
       "  'best_param': ({'splitter': 'best',\n",
       "    'min_samples_split': 16,\n",
       "    'min_samples_leaf': 5,\n",
       "    'max_depth': 10,\n",
       "    'criterion': 'entropy'},),\n",
       "  'best_sc': 0.8363873409645134},\n",
       " {'model': 'SVC',\n",
       "  'acc_score': 0.830078125,\n",
       "  'train_score': 0.8380615756673798,\n",
       "  'best_param': ({'kernel': 'rbf', 'decision_function_shape': 'ovr', 'C': 1},),\n",
       "  'best_sc': 0.8318294393407697},\n",
       " {'model': 'RandomForestClassifier',\n",
       "  'acc_score': 0.8430989583333334,\n",
       "  'train_score': 0.8879174030322761,\n",
       "  'best_param': ({'n_estimators': 250,\n",
       "    'min_samples_split': 20,\n",
       "    'min_samples_leaf': 1,\n",
       "    'max_depth': 75,\n",
       "    'criterion': 'gini'},),\n",
       "  'best_sc': 0.8447586445553495}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-4.07951788, -3.86841838, -3.75311423, ...,  3.75311423,\n",
       "          3.86841838,  4.07951788]),\n",
       "  array([ 1,  1,  1, ..., 99, 99, 99], dtype=int64)),\n",
       " (11.243888076209526, 40.94931310632202, 0.9380274835079963))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.stats.probplot(df['hours-per-week'],dist=\"norm\",plot=pylab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Working\\Ineuron_intership\\notebook\\EDA\\Final_model.ipynb Cell 62\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Working/Ineuron_intership/notebook/EDA/Final_model.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sns\u001b[39m.\u001b[39;49mscatterplot(x\u001b[39m=\u001b[39;49mX_train,y\u001b[39m=\u001b[39;49mX_test,hue\u001b[39m=\u001b[39;49mdf[\u001b[39m\"\u001b[39;49m\u001b[39msex\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\seaborn\\relational.py:603\u001b[0m, in \u001b[0;36mscatterplot\u001b[1;34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatterplot\u001b[39m(\n\u001b[0;32m    595\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[0;32m    596\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, style\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    601\u001b[0m ):\n\u001b[1;32m--> 603\u001b[0m     p \u001b[39m=\u001b[39m _ScatterPlotter(\n\u001b[0;32m    604\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    605\u001b[0m         variables\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, hue\u001b[39m=\u001b[39;49mhue, size\u001b[39m=\u001b[39;49msize, style\u001b[39m=\u001b[39;49mstyle),\n\u001b[0;32m    606\u001b[0m         legend\u001b[39m=\u001b[39;49mlegend\n\u001b[0;32m    607\u001b[0m     )\n\u001b[0;32m    609\u001b[0m     p\u001b[39m.\u001b[39mmap_hue(palette\u001b[39m=\u001b[39mpalette, order\u001b[39m=\u001b[39mhue_order, norm\u001b[39m=\u001b[39mhue_norm)\n\u001b[0;32m    610\u001b[0m     p\u001b[39m.\u001b[39mmap_size(sizes\u001b[39m=\u001b[39msizes, order\u001b[39m=\u001b[39msize_order, norm\u001b[39m=\u001b[39msize_norm)\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\seaborn\\relational.py:390\u001b[0m, in \u001b[0;36m_ScatterPlotter.__init__\u001b[1;34m(self, data, variables, legend)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, variables\u001b[39m=\u001b[39m{}, legend\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    382\u001b[0m \n\u001b[0;32m    383\u001b[0m     \u001b[39m# TODO this is messy, we want the mapping to be agnostic about\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[39m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     \u001b[39m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_size_range \u001b[39m=\u001b[39m (\n\u001b[0;32m    387\u001b[0m         np\u001b[39m.\u001b[39mr_[\u001b[39m.5\u001b[39m, \u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msquare(mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m\"\u001b[39m\u001b[39mlines.markersize\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    388\u001b[0m     )\n\u001b[1;32m--> 390\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data\u001b[39m=\u001b[39;49mdata, variables\u001b[39m=\u001b[39;49mvariables)\n\u001b[0;32m    392\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegend \u001b[39m=\u001b[39m legend\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\seaborn\\_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[39m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[39m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_ordered \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m}  \u001b[39m# alt., used DefaultDict\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massign_variables(data, variables)\n\u001b[0;32m    636\u001b[0m \u001b[39m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[39mfor\u001b[39;00m var \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mhue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstyle\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\seaborn\\_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m     \u001b[39m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[39m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[0;32m    677\u001b[0m     \u001b[39m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlong\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     plot_data \u001b[39m=\u001b[39m PlotData(data, variables)\n\u001b[0;32m    680\u001b[0m     frame \u001b[39m=\u001b[39m plot_data\u001b[39m.\u001b[39mframe\n\u001b[0;32m    681\u001b[0m     names \u001b[39m=\u001b[39m plot_data\u001b[39m.\u001b[39mnames\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\seaborn\\_core\\data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     53\u001b[0m     data: DataSource,\n\u001b[0;32m     54\u001b[0m     variables: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, VariableSpec],\n\u001b[0;32m     55\u001b[0m ):\n\u001b[0;32m     57\u001b[0m     data \u001b[39m=\u001b[39m handle_data_source(data)\n\u001b[1;32m---> 58\u001b[0m     frame, names, ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assign_variables(data, variables)\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe \u001b[39m=\u001b[39m frame\n\u001b[0;32m     61\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m names\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\seaborn\\_core\\data.py:265\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    260\u001b[0m             ids[key] \u001b[39m=\u001b[39m \u001b[39mid\u001b[39m(val)\n\u001b[0;32m    262\u001b[0m \u001b[39m# Construct a tidy plot DataFrame. This will convert a number of\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m# types automatically, aligning on index in case of pandas objects\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# TODO Note: this fails when variable specs *only* have scalars!\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m frame \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(plot_data)\n\u001b[0;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m frame, names, ids\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    116\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32me:\\Working\\Ineuron_intership\\venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:642\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    640\u001b[0m         raw_lengths\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(val))\n\u001b[0;32m    641\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(val, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m val\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 642\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    644\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indexes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m    645\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf using all scalar values, you must pass an index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "sns.scatterplot(x=X_train,y=X_test,hue=df[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'devmandloi37'\n",
    "password = 'Devendra123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'mongodb+srv://devmandloi37:devmandloi@cluster0.rkgp8jf.mongodb.net/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "client= pymongo.MongoClient(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = client.batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database(MongoClient(host=['ac-wedyuwc-shard-00-00.rkgp8jf.mongodb.net:27017', 'ac-wedyuwc-shard-00-01.rkgp8jf.mongodb.net:27017', 'ac-wedyuwc-shard-00-02.rkgp8jf.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-xhmlyt-shard-0', tls=True), 'batch_data')\n"
     ]
    }
   ],
   "source": [
    "print(dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database(MongoClient(host=['ac-wedyuwc-shard-00-00.rkgp8jf.mongodb.net:27017', 'ac-wedyuwc-shard-00-01.rkgp8jf.mongodb.net:27017', 'ac-wedyuwc-shard-00-02.rkgp8jf.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-xhmlyt-shard-0', tls=True), 'test')\n"
     ]
    }
   ],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = client['Income_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = DB['test_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "\n",
    "uri = \"mongodb+srv://devmandloi37:devmandloi@cluster0.rkgp8jf.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB = client['Income_prediction']\n",
    "collect = DB['test_data']\n",
    "\n",
    "DB.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['family', 'scraper', 'admin', 'local']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb=client[\"mydatabase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycol=mydb[\"myfirstcollection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['family', 'scraper', 'admin', 'local']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfirstrecord={\"fname\":\"sunny\",\"lname\":\"savita\",\"address\":\"bengaluru\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x1c295841820>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycol.insert_one(myfirstrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysecondrecord={\"fname\":\"krish\",\"lname\":\"naik\",\"address\":\"bengaluru urban\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
